% !TeX TXS-program:compile = txs:///knit2pdf
\documentclass[12pt]{mwart}
\usepackage[utf8]{inputenc}
\usepackage[T1,plmath]{polski}
\usepackage{lmodern}

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{float}

\title{Sprawozdanie 3}
\author{Aleksander Jakóbczyk i Kacper Pasterniak}
\date{}

\begin{document}
\maketitle

<<warning=F, message=F,echo = F>>=
library(binom)
require(ggplot2)
library(reshape2)
library(xtable)
library(vcdExtra)
library(tidyverse)
library(matrixStats)
# pdf.options(encoding = 'ISOLatin2') # znaki polskie w wykresach
library(DescTools)
library(stats)
library(base)
library(matlib)
library(exact2x2)
library(gnm)
library(MASS)

@
\section*{Lista 10}
\subsection*{Zadanie 1}
W tabeli 1 zawarte są wyniki (w skali pozytywny, negatywny) z pierwszego i drugiego
kolokwium w pewnej grupie studentów. Przyjmując, że poziom trudności zadań na
pierwszym i drugim kolokwium był taki sam, na podstawie tych danych, zweryfikować hipotezę, na poziomie istotności 0.05, że studenci byli tak samo przygotowani
do obu kolokwiów.\newline

% <<results = F, echo = F>>=
% data <- matrix(c(
%   32,44,76,22,38,60,54,82,136), 3, 3, byrow = T)
% dimnames(data) <- list(
%   `Wynik z kolokwium 2` =
%     c("Negatywny", "Pozytywny","Suma"),
%   `Wynik z kolokwium 1` = c("Negatywny","Pozytywny","suma"))
% @
<<tab1,echo=FALSE,message=FALSE,result='hide',warning=FALSE,fig.height=7,fig.pos="h">>=
knitr::include_graphics("nowyfolder/1.png")
@

<<results = F, echo = F>>=
data <- matrix(c(32,44,
                 22,38), 2, 2, byrow = T)
data
dimnames(data) <- list(
  wyniki_z_1 = c("F", "T"),
  wyniki_z_2 = c("F", "T")
)
data
@
<<>>=
mcnemar.test(data,correct = FALSE)

zad1 <- function(data) {
  y12 <- data[1,2]
  y21 <- data[2,1]
  z0  <- ( y12 - y21 ) / ( sqrt( y12 + y21 ) )  
  p <- 1 - pchisq(z0^2, df = 1)
  return(p)
}
zad1(data)
@
\newpage
Dla danych w Tabeli 1. przeprowadziliśmy test McNemary'ego i test $Z_{0}$ i na poziomie istotności 0.05 odrzucamy hipotezę, że studenci byli tak samo przygotowani do obu kolokwiów. Z obu testów otrzymaliśmy takie same p-wartości równe 0.006768741.
\subsection*{Zadanie 2}
W tabeli 2 zawarte są dane dotyczące reakcji po godzinie od przyjęcia dwóch różnych
leków przeciwbólowych (powiedzmy A i B) stosowanych w migrenie, zaaplikowanych
grupie pacjentów w dwóch różnych atakach bólowych. Na podstawie tych danych,
zweryfikować hipotezę, że leki te są jednakowo skuteczne korzystając z testu:
\begin{enumerate}
  \item McNemary’ego z poprawką na ciągłość, 
  \item dokładnego (opisanego w sekcji 2.1.3 wykładu 9. do wydruku) 
\end{enumerate}

W drugim przypadku, najpierw napisać deklarację funkcji, której wartością będzie
wartość poziomu krytycznego (p wartość) w tym warunkowym teście dokładnym.\newline\newline
<<tab2,echo=FALSE,message=FALSE,result='hide',warning=FALSE,fig.height=7,fig.pos="h">>=
knitr::include_graphics("nowyfolder/2.png")
@
\subsection*{1)}
<<results = F, echo = F>>=
  data2 <- matrix(c(1,5,
                  2,4), 2, 2, byrow = T)
  dimnames(data2) <- list(
  wyniki_z_1 = c("F", "T"),
  wyniki_z_2 = c("F", "T"))
@
<<>>=
  zad2 <- function(data, correct = TRUE) {
    y12 <- data[1,2]
    y21 <- data[2,1]
    if (correct) {
      z0 <- (abs( y12 - y21 ) - 1)/sqrt(y12 + y21)
    } else {
      z0  <- ( y12 - y21 ) / ( sqrt( y12 + y21 ) )  
    }
    p <- 1 - pchisq(z0^2, df = 1)
    return(p)
  }
mcnemar.test(data2,correct = TRUE)
zad2(data2)
@
Na poziomie istotności 0.05, nie mamy podstaw do odrzucenia hipotezy o tym, że leki są jednakowo skuteczne. Wartość poziomu krytycznego zarówno w teście McNemary z poprawką na ciągłość i teście $Z_{0}$ wynosi 0.4496918.
\subsection*{2)}
<<>>=
zad2b <- function(data) {
  y12 <- data[1,2]
  y21 <- data[2,1]
  if (y12 < (y12+y21)/2) {
    p <- 2*sum(sapply(0:y12, 
      function(k) choose(y12+y21,k) * (1/2)^k * (1/2)^(y12+y21-k)))
  } else if (y12 > (y12+y21)/2) {
    p <- 2*sum(sapply(y12:(y12+y21), 
      function(k) choose(y12+y21,k) * (1/2)^k * (1/2)^(y12+y21-k)))
  } else {
    p <- 1
  }
  return(p)
}

zad2b(data2)
mcnemar.exact(data2)$p.value
@
W 2. podpunkcie przeprowadziliśmy warunkowy test dokładny, wynik porówaliśmy z wbudowanym testem. McNemary z biblioteki $\textbf{exact2x2}$. Jak możemy zauważyć, p-wartości są sobie równe w tych dwóch metodach i wynoszą 0.453125, co dla poziomu istotności 0.05 nie daje nam podstaw do odrzucenia hipotezy o tym, że leki są jednakowo skuteczne.\newpage
\subsection*{Zadanie 3}
Przeprowadzić symulacje, w celu porównania mocy testu Z (opisanego w sekcji
2.1.1) i testu $Z_{0}$ (opisanego w sekcji 2.1.2). Wyniki przedstawić w tabeli lub/i na
wykresach i napisać odpowiednie wnioski.
<<>>=
n <- 10
mcs <- 1000
alpha <- 0.05
ps_1 <- numeric(mcs)
ps_2 <- numeric(mcs)
p2 <- seq(0.01,0.99,0.02)
p2_0 <- 0.5
@


<<warning=F, message=F>>=
f_to_sup <- function(p) {
  p2 <- p
  for (mc in 1:mcs) {
    X <- rbinom(n,1, p = 0.5)
    Y <- rbinom(n, 1, p = p2)
    data <- matrix(0, nrow = 2, ncol = 2)
    for (i in 1:n) {
      x<-X[i]
      y<-Y[i]
      if (x==0 & y==0) {
        data[1,1] <- data[1,1] + 1
      } else if (x==0 & y==1){
        data[1,2] <- data[1,2] + 1
      }
      else if (x==1 & y==0){
        data[2,1] <- data[2,1] + 1
      } else{
        data[2,2] <- data[2,2] + 1
      }
    }
    y12 <- data[1,2]
    y21 <- data[2,1]
    p_data <- data/n
    p11 <- p_data[1,1]
    p12 <- p_data[1,2]
    p21 <- p_data[2,1]
    p22 <- p_data[2,2]
    
    p_.1 <- (data[1,1]+data[2,1])/n
    p_1. <- (data[1,1]+data[1,2])/n
    D <- p_1. - p_.1
    sig <- sqrt( ( p_1.*(1-p_1.) + p_.1*(1-p_.1) - 2*(p11*p22-p12*p21) )/n  )
    z <- D/sig
    p_value1 <- 2*(1 - pnorm(abs(z)))
    z0  <- ( y12 - y21 ) / ( sqrt( y12 + y21 ) )  
    p_value2 <- 2*(1 - pnorm(abs(z0)))
    ps_1[mc] <- p_value1 < 0.05
    ps_2[mc] <- p_value2 < 0.05
  }
  return(c( sum(ps_1, na.rm = TRUE)/mcs,
            sum(ps_2, na.rm = TRUE)/mcs))
}
f_to_sup_error_rm <- function(x){
  tryCatch(
    expr = {
      return(f_to_sup(x))
    },
    error = function(e){
    },
    warning = function(w){
      f_to_sup(x)
    },
    finally = {
    }
  )    
}
sym <- sapply(p2, f_to_sup_error_rm)
df <- data.frame(p2 = p2, Z0 = sym[1,], Z = sym[2,] )
melt_Df <- melt(df, id=1, measure=c("Z","Z0"))
@

<<fig.width = 12, fig.height = 8, echo = F, fig.cap ='\\label{fig:1} Porównanie mocy testów' ,fig.pos = 'H'>>=
theme_update(# axis labels
             axis.title = element_text(size = 27),
             # tick labels
             axis.text = element_text(size = 20),
             # title 
             title = element_text(size = 22),
             legend.text = element_text(size=20))
ggplot(melt_Df,aes(p2, value, colour = variable)) + 
geom_point() + geom_line() 
@
\newpage
\subsection*{Wnioski do Zadania 3}
nie wiem co tu
\section*{Lista 11}
\subsection*{Zadanie 1}
W tabeli 1 zawarte są wyniki (w skali 2, 3, +3, 4, +4, 5) z pierwszego i drugiego
kolokwium w pewnej grupie studentów. Korzystając z odpowiedniego testu, na poziomie istotności $\alpha$ = 0.05, zweryfikować hipotezę, że dane w tabeli 1 podlegają modelow:
\begin{enumerate}
  \item symetrii, 
  \item quasi-symetriim 
  \item quasi-niezależności. 
\end{enumerate}
Zwrócić uwagę na problem z zastosowaniem do analizowanych danych testu Bowkera

\subsubsection{Testowanie symetrii za pomocą testu ilorazu wiarygodności}
<<echo= F, message=F,result='hide'>>=
count <- c(5,2,1,0,0,0,6,3,2,2,0,0,1,4,5,5,2,2,0,10,15,18,5,2,1,2,5,3,2,2,0,1,3,4,3,2)
kol1<- gl(6,6,labels=c("2","3","+3","4","+4","5"))
kol2 <- gl(6,1,labels=c("2","3","+3","4","+4","5"))
dane33 <- data.frame(kol1,kol2,count)
#dane3
symmetry <- glm(count ~ Symm(kol1, kol2), data=dane33, family = poisson)
#summary(symmetry)
x = symmetry$deviance
#x
r = 15
p = 1-pchisq(x,r)
@
<<>>=
symmetry <- glm(count ~ Symm(kol1, kol2), data=dane33, 
                family = poisson) 
x = symmetry$deviance #wartość statystyki G^2
r=15 #Liczba stopni swobody
1-pchisq(x,r) #p-wartość
@
Do przetestowania symetrii dla danych w Tabeli 1. wykorzystaliśmy test ilorazu wiarygodności (IW), aby to zrobić musieliśmy przekształcić dane do postaci ramki danych. Następnie za pomocą funkcji $\textbf{glm}$ z biblioteki $\textbf{gnm}$ przeprowadziliśmy test symetrii. P-wartość owego testu wyznaczyliśmy za pomocą wzoru : $\textbf{1-pchisq(x,r)}$, gdzie $\textbf{pchisq}$ jest dystrybuantą rozkładu $\chi^{2}$, $\textbf{x}$ to wartość statystyki $G^{2}$ z testu, a $\textbf{r}$ to ilość stopni swobody. \newline Na poziomie istotności 0.05 nie mamy podstaw do odrzucenia hipotezy o symetrii. Wartość poziomu krytycznego wynosi 0.1004656. 

\subsubsection{Testowanie quasi-symetrii}
Hipotezę zerową, że dane podlegają modelowi quasi-symetrii również zweryfikujemy korzystając z funkcji $\textbf{glm}$.
<<>>=
quasi.symm <- glm(count ~ kol1+kol2 + Symm(kol1,kol2),
                  data=dane33, family =poisson)
x = quasi.symm$deviance #wartość statystyki G^2
r=10 #Liczba stopni swobody
1-pchisq(x,r) #p-wartość
@
Korzystając z testu ilorazu wiarygodności (IW), na poziomie istotności 0.05, nie ma podstaw do odrzucenia hipotezy o quasi-symetrii. Wartość poziomu krytycznego w teście wynosi  0.9589187. 

\subsubsection{Testowanie quasi-niezależności}
Hipotezę zerową, że dane podlegają modelowi quasi niezależności również zweryfikujemy korzystając z funkcji $\textbf{glm}$.

<<>>=
quasi.indep <- glm(count ~ kol1 + kol2 + Diag(kol1, kol2),
                   data=dane33, family = poisson)
x=quasi.indep$deviance #wartość statystyki G^2
r = 19 #Liczba stopni swobody
1-pchisq(x,r) #p-wartość
@
Korzystając, z testu ilorazu wiarogodności (IW), na poziomie istotności 0.05, hipotezę o quasi-niezależności należy odrzucić.
Wartość poziomu krytycznego w tym teście wynosi 0.00962481.



\subsection*{Zadanie 2}
W tabeli 3 zawarte są wyniki (w skali 2, 3, +3, 4, +4, 5) z pierwszego i drugiego
kolokwium w pewnej grupie studentów. Przyjmując, że poziom trudności zadań na
pierwszym i drugim kolokwium był taki sam, na podstawie tych danych, zweryfikować hipotezę, na poziomie istotności 0.05, że studenci byli tak samo przygotowani
do obu kolokwiów.\newline\newline
<<tab3,echo=FALSE,message=FALSE,result='hide',warning=FALSE,fig.height=7,fig.pos="h">>=
knitr::include_graphics("nowyfolder/3.png")
@

<<>>=
comparison <- anova(symmetry, quasi.symm)
p <- 1-pchisq(comparison$Deviance[2], comparison$Df[2])
p
@

\newpage
\section*{Lista 12,13 i 14}
Wszystkie poniższe zadania należy wykonać w oparciu o dane w pliku Ankieta.csv,
które zawieraj ,
a wyniki ankietowania 40 losowo wybranych studentów PWr. Ankieta zawierała trzy pytania, które dotyczyły jakości snu (odpowiedź 1 oznaczała, że student sypia
dobrze, 0, że źle), czy regularnie biega (1 – tak, 0 – nie) oraz czy posiada psa (1 – tak, 0
– nie).
\subsection*{Zadanie 1}
W przypadku powyższych danych, podać interpretację następujących modeli logliniowych:
\begin{itemize}
  \item[$\blacksquare$] \textbf{[1 3]}, \newline
  $ l_{ij} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(3)}, \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $, \newline Zmienne $W_{1}$ i $W_{3}$ mają dowolne rozkłady oraz zmienne te są niezależne. 
  \item[$\blacksquare$] \textbf{[13]},\newline
  $ l_{ij} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(3)} + \lambda_{ij}^{(13)}, \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $, \newline Zmienne $W_{1}$ i $W_{3}$ mają dowolne rozkłady oraz zmienne te nie są niezależne. 
  \item[$\blacksquare$] \textbf{[1 2 3]},\newline
  $ l_{ijk} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(2)}  + \lambda_{k}^{(3)}, \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $ i $k \in \{1,...,L\} $, \newline Zmienne $W_{1}$ i $W_{2}$ i $W_{3}$ są wzajemnie niezależne. 
  \item[$\blacksquare$] \textbf{[12 3]},\newline
  $ l_{ijk} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(2)} +\lambda_{k}^{(3)}+ \lambda_{ij}^{(12)},\newline \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $ i $k \in \{1,...,L\} $, \newline Zmienna $W_{3}$ jest niezależna od zmiennej $W_{1}$ i $W_{2}$, ale zmienne $W_{1}$ i $W_{2}$ nie są niezależne.  
  \item[$\blacksquare$] \textbf{[12 13]},\newline
$ l_{ijk} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(2)}  + \lambda_{k}^{(3)}+ \lambda_{ij}^{(12)}+ \lambda_{ik}^{(13)},\newline \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $ i $k \in \{1,...,L\} $, \newline Przy ustalonej wartości zmiennej $W_{1}$, zmienne $W_{2}$ i $W_{3}$ są niezależne. Mówimy wówczas, że zmienne $W_{2}$ i $W_{3}$ są warunkowo niezależne.
  \item[$\blacksquare$] \textbf{[1 23]}.\newline
  $ l_{ijk} = \lambda + \lambda_{i}^{(1)}+ \lambda_{j}^{(2)} +\lambda_{k}^{(3)}+ \lambda_{jk}^{(23)},\newline \forall i \in \{1,...,R\}$ i $j \in \{1,...,C\} $ i $k \in \{1,...,L\} $, \newline Zmienna $W_{1}$ jest niezależna od zmiennej $W_{2}$ i $W_{3}$, ale zmienne $W_{2}$ i $W_{3}$ nie są niezależne. 
\end{itemize}
\subsection*{Zadanie 2}
Przyjmując model log-liniowy [12 3], na podstawie danych Ankieta.csv, oszacować
prawdopodobieństwo:
\begin{enumerate}
  \item dobrej jakości snu studenta, który regularnie biega,
  \item tego, że student biega regularnie, gdy posiada psa.
\end{enumerate}
Jakie byłyby oszacowania powyższych prawdopodobieństw przy założeniu modelu [12 23]?

<<>>=
dane <- read.csv("Ankieta.csv",sep = ";")
sen <- dane[,1]
bieganie <- dane[,2]
pies <- dane[,3]
ankieta <- table(sen, bieganie, pies)
ankieta.df <- as.data.frame(as.table(ankieta))
@
\subsection*{Model [12 3]}
<<>>=
mod1 <- glm(Freq ~ sen + bieganie + pies + sen*bieganie, 
            data = ankieta.df, family = poisson)
diff <- cbind(mod1$data, fitted(mod1))
diff
@

\subsubsection*{Pytanie 1.}

<<>>=
La_mod1_fitt<-sum(diff[diff["sen"] == 1&diff["bieganie"] ==1,]["fitted(mod1)"])
Ma_mod1_fitt<-sum(diff[diff["bieganie"] == 1,]["fitted(mod1)"])
pa_mod1_fitt<-La_mod1_fitt/Ma_mod1_fitt
pa_mod1_fitt

La_mod1_date <- sum(diff[diff["sen"] == 1&diff["bieganie"] == 1,]["Freq"])
Ma_mod1_date <- sum(diff[diff["bieganie"] == 1,]["Freq"])
pa_mod1_date <- La_mod1_date/Ma_mod1_date
pa_mod1_date
@

\subsubsection*{Pytanie 2.}

<<>>=
Lb_mod1_fitt<-sum(diff[diff["bieganie"] ==1&diff["pies"] == 1 ,]["fitted(mod1)"])
Mb_mod1_fitt<-sum(diff[diff["pies"] ==1,]["fitted(mod1)"])
pb_mod1_fitt<-Lb_mod1_fitt/Mb_mod1_fitt
pb_mod1_fitt

Lb_mod1_date <- sum(diff[diff["bieganie"] ==1&diff["pies"] == 1 ,]["Freq"])
Mb_mod1_date <- sum(diff[diff["pies"] ==1,]["Freq"])
pb_mod1_date <- Lb_mod1_date/Mb_mod1_date
pb_mod1_date
@

\subsection*{Model [12 23]}
<<>>=
mod2 <- glm(Freq ~ sen + bieganie + pies + sen*bieganie + bieganie*pies, 
            data = ankieta.df, family = poisson)
diff <- cbind(mod2$data, fitted(mod2))
diff
@

\subsubsection*{Pytanie 1.}

<<>>=
La_mod2_fitt<-sum(diff[diff["sen"] == 1&diff["bieganie"] ==1,]["fitted(mod2)"])
Ma_mod2_fitt<-sum(diff[diff["bieganie"] == 1,]["fitted(mod2)"])
pa_mod2_fitt<-La_mod2_fitt/Ma_mod2_fitt
pa_mod2_fitt

La_mod2_date <- sum(diff[diff["sen"] == 1&diff["bieganie"] == 1,]["Freq"])
Ma_mod2_date <- sum(diff[diff["bieganie"] == 1,]["Freq"])
pa_mod2_date <- La_mod2_date/Ma_mod2_date
pa_mod2_date
@

\subsubsection*{Pytanie 2.}

<<>>=
Lb_mod2_fitt<-sum(diff[diff["bieganie"] ==1&diff["pies"] == 1 ,]["fitted(mod2)"])
Mb_mod2_fitt<-sum(diff[diff["pies"] ==1,]["fitted(mod2)"])
pb_mod2_fitt<-Lb_mod2_fitt/Mb_mod2_fitt
pb_mod2_fitt

Lb_mod2_date <- sum(diff[diff["bieganie"] ==1&diff["pies"] == 1 ,]["Freq"])
Mb_mod2_date <- sum(diff[diff["pies"] ==1,]["Freq"])
pb_mod2_date <- Lb_mod2_date/Mb_mod2_date
pb_mod2_date
@


\subsection*{Zadanie 3}
Na podstawie danych Reakcja3.csv zweryfikować następujące hipotezy:

\begin{enumerate}
  \item zmienne losowe Sen, Bieganie i Pies są wzajemnie niezależne,
  \item zmienna losowa Pies jest niezależna od pary zmiennych Sen i Bieganie,
  \item zmienna losowa Sen jest niezależna od zmiennej Pies, przy ustalonej zmiennej
Bieganie.
\end{enumerate}

\subsection*{Pytanie 1.}

<<>>=
mod1 <- glm(Freq ~ sen + bieganie + pies, 
            data = ankieta.df, family = poisson)
mod2 <- glm(Freq ~ (sen + bieganie + pies)^2, 
            data = ankieta.df, family = poisson)
mod3 <- glm(Freq ~ (sen + bieganie + pies)^3, 
            data = ankieta.df, family = poisson)
@
<<>>=
test1 <- anova(mod1,mod2)
1-pchisq(test1$Deviance[2], df = test1$Df[2])
test2 <- anova(mod1,mod3)
1-pchisq(test2$Deviance[2], df = test2$Df[2])
@

\subsection*{Pytanie 2.}
<<>>=
mod1 <- glm(Freq ~ sen + bieganie + pies + sen*bieganie, 
            data = ankieta.df, family = poisson)
mod2 <- glm(Freq ~ (sen + bieganie + pies)^2, 
            data = ankieta.df, family = poisson)
mod3 <- glm(Freq ~ (sen + bieganie + pies)^3, 
            data = ankieta.df, family = poisson)
@
<<>=
test1 <- anova(mod1,mod2)
1-pchisq(test1$Deviance[2], df = test1$Df[2])
test2 <- anova(mod1,mod3)
1-pchisq(test2$Deviance[2], df = test2$Df[2])
@

\subsection*{Pytanie 3.}

<<>>=
mod1 <- glm(Freq ~ sen + bieganie + pies + sen*bieganie + pies*bieganie, 
            data = ankieta.df, family = poisson)
mod2 <- glm(Freq ~ (sen + bieganie + pies)^2, 
            data = ankieta.df, family = poisson)#model niepełny
mod3 <- glm(Freq ~ (sen + bieganie + pies)^3, 
            data = ankieta.df, family = poisson)#model pełny
@
<<>>=
mod2 <- glm(Freq ~ (sen + bieganie + pies)^2, 
            data = ankieta.df, family = poisson)#model niepełny
mod3 <- glm(Freq ~ (sen + bieganie + pies)^3, 
            data = ankieta.df, family = poisson)#model pełny
@

\subsection*{Zadanie 4}
Na podstawie danych Ankieta.csv dokonać wyboru modelu w oparciu o:
\begin{enumerate}
  \item testy,
  \item kryterium AIC,
  \item kryterium BIC.
\end{enumerate}
W przypadku, gdy wybrane modele w punktach 1–3 są różne, dokonać ich porównania.
\subsection*{Wszystkie 19 modeli}
<<>>=
#123
mod123 <- glm(Freq ~ sen + bieganie + pies + 
                  sen*bieganie + 
                  sen*pies +
                  bieganie*pies+
                  sen*bieganie*pies, 
            data = ankieta.df, family = poisson)
#12 13 23
mod12_13_23 <- glm(Freq ~ sen + bieganie + pies + 
              sen*bieganie + 
              sen*pies +
              bieganie*pies, 
            data = ankieta.df, family = poisson)

#12 13
mod12_13 <- glm(Freq ~ sen + bieganie + pies + 
            sen*bieganie + 
            sen*pies, 
            data = ankieta.df, family = poisson)

#12 23
mod12_23 <- glm(Freq ~ sen + bieganie + pies + 
              sen*bieganie +
              bieganie*pies, 
            data = ankieta.df, family = poisson)

#13 23
mod13_23 <- glm(Freq ~ sen + bieganie + pies + 
              sen*pies +
              bieganie*pies, 
            data = ankieta.df, family = poisson)

#12 3
mod12_3 <- glm(Freq ~ sen + bieganie + pies + 
                  sen*bieganie,
                data = ankieta.df, family = poisson)

#13 2
mod13_2 <- glm(Freq ~ sen + bieganie + pies + 
                 sen*pies,
               data = ankieta.df, family = poisson)

#23 1
mod23_1 <- glm(Freq ~ sen + bieganie + pies + 
                 bieganie*pies,
               data = ankieta.df, family = poisson)
#12
mod12 <- glm(Freq ~ sen + bieganie + 
                 sen*bieganie,
               data = ankieta.df, family = poisson)
#13
mod13 <- glm(Freq ~ sen + pies + 
               sen*pies,
             data = ankieta.df, family = poisson)
#23
mod23 <- glm(Freq ~  bieganie + pies +  
               bieganie*pies,
             data = ankieta.df, family = poisson)
#1 2 3
mod1_2_3 <- glm(Freq ~ sen + bieganie + pies,
             data = ankieta.df, family = poisson)

#1 2
mod1_2 <- glm(Freq ~ sen + bieganie ,
                data = ankieta.df, family = poisson)

#1 3
mod1_3 <- glm(Freq ~ sen + pies,
                data = ankieta.df, family = poisson)

#2 3
mod2_3 <- glm(Freq ~ bieganie + pies,
                data = ankieta.df, family = poisson)
#1
mod1 <- glm(Freq ~ sen,
                data = ankieta.df, family = poisson)

#2
mod2 <- glm(Freq ~ bieganie,
                data = ankieta.df, family = poisson)
#3
mod3 <- glm(Freq ~ pies,
                data = ankieta.df, family = poisson)

#staly
mod0 <- glm(Freq ~ 1,
                data = ankieta.df, family = poisson)
@

\subsection*{Pytanie 1.}
<<>>=
test1 <- anova(mod1_2_3, mod13_2)
1-pchisq(test1$Deviance[2], df = test1$Df[2]) # wybieramy mod1_2_3

test2 <- anova(mod1_2_3, mod12_3)
1-pchisq(test2$Deviance[2], df = test2$Df[2]) # wybieramy mod12_3

test3 <- anova(mod12_3, mod12_13)
1-pchisq(test3$Deviance[2], df = test3$Df[2]) # wybieramy mod12_3

test4 <- anova(mod13_2, mod13_23)
1-pchisq(test4$Deviance[2], df = test4$Df[2]) # wybieramy mod12_3
@

\subsection*{Pytanie 2.}
<<>>=
AIC(mod123)
AIC(mod12_13_23)
AIC(mod12_13)
AIC(mod12_23)
AIC(mod13_23)
AIC(mod12_3)
AIC(mod13_2)
AIC(mod23_1)
AIC(mod12)
AIC(mod13)
AIC(mod23)
AIC(mod1_2_3)
AIC(mod1_2)
AIC(mod1_3)
AIC(mod2_3)
AIC(mod1)
AIC(mod2)
AIC(mod3)
AIC(mod0)
@
Minimum dla modelu [12,23].
Podobnie mozemu uzyć funkcji \textit{step}:
<<>>=
step(mod123)
@
Otrzymujemy minimarium warotsc kryterium AIC dla modelu [12,23]
\subsection*{Pytanie 3.}
<<>>=
BIC(mod123)
BIC(mod12_13_23)
BIC(mod12_13)
BIC(mod12_23)
BIC(mod13_23)
BIC(mod12_3)
BIC(mod13_2)
BIC(mod23_1)
BIC(mod12)
BIC(mod13)
BIC(mod23)
BIC(mod1_2_3)
BIC(mod1_2)
BIC(mod1_3)
BIC(mod2_3)
BIC(mod1)
BIC(mod2)
BIC(mod3)
BIC(mod0)
@
Minimum dla modelu [12,23].
Podobnie mozemu uzyć funkcji \textit{step} z criterion = "BIC" :
<<>>=
step(mod123,criterion = "BIC")
@
Otrzymujemy minimarium warotsc kryterium AIC dla modelu [12,23]

Czyli kazda z powyzej przedstawionych  metod prowadzi nas do tego samego wyniku.
\end{document}